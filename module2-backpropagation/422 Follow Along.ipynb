{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np = np.random.seed(812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(([2, 9],\n",
    "             [1, 5],\n",
    "             [3, 6]),dtype=float)\n",
    "y = np.array (([90],\n",
    "              [72],\n",
    "              [80]),dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X/np.amax(X, axis=0)\n",
    "y=y/100\n",
    "\n",
    "#normalizing data - max normalization on X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.inputs=2\n",
    "        self.hiddenNodes=3\n",
    "        self.outputNodes=1\n",
    "        # no bias in this example - keep in mind\n",
    "        # initialize weight 2x3 input X hidden\n",
    "        self.weights1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "        \n",
    "        # initialize weights 3x1 hidden X output\n",
    "        self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        sx = self.sigmoid(s)\n",
    "        return sx * (1-sx)\n",
    "    \n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        self.final_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.final_output\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        \"\"\"\n",
    "        Backprop thru network\n",
    "        \"\"\"\n",
    "        self.o_error = y - o\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(self.output_sum)\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.hidden_sum)\n",
    "        \n",
    "        self.weights1 += X.T.dot(self.z2_delta) # adjust first set of weights\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X,y,o)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()\n",
    "nn.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78112341],\n",
       "       [0.59922654],\n",
       "       [0.70202301]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.o_error\n",
    "# error times derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First gradient - how much sigmoid activation would've pushed us to the right layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08181873],\n",
       "       [0.06363021],\n",
       "       [0.06204304]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.o_delta\n",
    "# error times derivative times sigmoid prime between output layer and z2 (activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11887659],\n",
       "       [0.12077346],\n",
       "       [0.09797699]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.sigmoid(nn.output_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10474495],\n",
       "       [0.10618723],\n",
       "       [0.0883775 ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.sigmoidPrime(nn.output_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the derivatives, how we need to related it to the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08181873],\n",
       "       [0.06363021],\n",
       "       [0.06204304]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# are these helping or hurting?\n",
    "nn.o_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06517483, -0.22381276, -0.02592879],\n",
       "       [-0.05068629, -0.17405859, -0.02016475],\n",
       "       [-0.04942199, -0.16971693, -0.01966177]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dot product of the o_delta and the weight gives us the propagated error\n",
    "nn.z2_error\n",
    "# for each input, have an error for each hidden neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00698305, -0.05480675, -0.00629866],\n",
       "       [-0.00951447, -0.04314046, -0.00501545],\n",
       "       [-0.00824883, -0.04202595, -0.00402255]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the product of the derivative sigmoid function - showing the slope of the relationship \n",
    "# between the node and the output - and the error that's been propagated to the second\n",
    "# weight layer.\n",
    "nn.z2_delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has same shape as inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We multiply the gradient by the inputs - why? so more effective - larger errors in larger inputs get larger adjustments.\n",
    "Why do we need to transpose the input? - error with respect to the weights in each observations. I still don't get it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66666667, 0.33333333, 1.        ],\n",
       "       [1.        , 0.55555556, 0.66666667]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01607569, -0.09294394, -0.00989347],\n",
       "       [-0.01776808, -0.10679097, -0.01176672]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T.dot(nn.z2_delta)\n",
    "# 2x3 - two input neurons into 3 hidden neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16843549],\n",
       "       [0.09796428],\n",
       "       [0.08136732]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.activated_hidden.T.dot(nn.o_delta)\n",
    "# weights\n",
    "# 3x1 - 3 neurons into 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "[[0.37771334]\n",
      " [0.41477855]\n",
      " [0.40348484]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.52228666],\n",
       "       [0.30522145],\n",
       "       [0.39651516]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "output = nn.feed_forward(X)\n",
    "print(X)\n",
    "print(output)\n",
    "error = y - output\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error high because prediction is low\n",
    "# prediction is low because random weights \n",
    "# specifically - either because the ssecond layer weights are low or the activation from first later are low\n",
    "# how is activation determined?\n",
    "# input * weights\n",
    "# no control over inputs\n",
    "# control over weights - need to increase weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.15855806]\n",
      " [0.15244832]\n",
      " [0.13028834]]\n",
      "Loss: \n",
      " 0.44012158591700096\n",
      "+---------EPOCH 2---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.21470235]\n",
      " [0.19633166]\n",
      " [0.17688981]]\n",
      "Loss: \n",
      " 0.37737590210695654\n",
      "+---------EPOCH 3---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.28938067]\n",
      " [0.25475515]\n",
      " [0.24058087]]\n",
      "Loss: \n",
      " 0.3007528345109189\n",
      "+---------EPOCH 4---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.37770888]\n",
      " [0.32572686]\n",
      " [0.3184181 ]]\n",
      "Loss: \n",
      " 0.2200534833092657\n",
      "+---------EPOCH 5---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.46691544]\n",
      " [0.40080611]\n",
      " [0.39979495]]\n",
      "Loss: \n",
      " 0.14987035317097464\n",
      "+---------EPOCH 1000---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.85493417]\n",
      " [0.75229242]\n",
      " [0.80093327]]\n",
      "Loss: \n",
      " 0.0010248667576153044\n",
      "+---------EPOCH 2000---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.86471286]\n",
      " [0.74179788]\n",
      " [0.80256701]]\n",
      "Loss: \n",
      " 0.0005756396757346077\n",
      "+---------EPOCH 3000---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.87231932]\n",
      " [0.73600922]\n",
      " [0.8020936 ]]\n",
      "Loss: \n",
      " 0.0003422994578252143\n",
      "+---------EPOCH 4000---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.87805371]\n",
      " [0.73214932]\n",
      " [0.80158932]]\n",
      "Loss: \n",
      " 0.0002105904913752249\n",
      "+---------EPOCH 5000---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.88243011]\n",
      " [0.72939905]\n",
      " [0.80122083]]\n",
      "Loss: \n",
      " 0.00013284452688182866\n",
      "+---------EPOCH 6000---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.88582391]\n",
      " [0.72737864]\n",
      " [0.80095111]]\n",
      "Loss: \n",
      " 8.54368103292663e-05\n",
      "+---------EPOCH 7000---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.88849047]\n",
      " [0.72585994]\n",
      " [0.80074998]]\n",
      "Loss: \n",
      " 5.579017124298426e-05\n",
      "+---------EPOCH 8000---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.89060814]\n",
      " [0.72469696]\n",
      " [0.80059737]]\n",
      "Loss: \n",
      " 3.68751351829401e-05\n",
      "+---------EPOCH 9000---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.89230467]\n",
      " [0.7237928 ]\n",
      " [0.8004798 ]]\n",
      "Loss: \n",
      " 2.461121755607385e-05\n",
      "+---------EPOCH 10000---------+\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.9 ]\n",
      " [0.72]\n",
      " [0.8 ]]\n",
      "Predicted Output: \n",
      " [[0.89367363]\n",
      " [0.7230811 ]\n",
      " [0.80038801]]\n",
      "Loss: \n",
      " 1.6555551048367513e-05\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        print('Input: \\n', X)\n",
    "        print('Actual Output: \\n', y)\n",
    "        print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
    "    nn.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S2-NN (Python3)",
   "language": "python",
   "name": "u4-s2-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
