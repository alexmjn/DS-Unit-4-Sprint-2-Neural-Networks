{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "#TODO add early stopping, dropout, regularization\n",
    "\n",
    "#Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "#Use Cross Validation techniques to get more consistent results with your model.\n",
    "#Use GridSearchCV to try different combinations of hyperparameters.\n",
    "#Start looking into other types of Keras layers for CNNs and RNNs maybe\n",
    "#try and build a CNN model for fashion-MNIST to see how the results compar\n",
    "\n",
    "#feature engineering - remove outliers, etc. run pandas profiling\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "#https://www.tensorflow.org/tutorials/keras/save_and_load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, 0.00000e+00, 5.38000e-01,\n",
       "        6.14200e+00, 9.17000e+01, 3.97690e+00, 4.00000e+00, 3.07000e+02,\n",
       "        2.10000e+01, 3.96900e+02, 1.87200e+01],\n",
       "       [2.17700e-02, 8.25000e+01, 2.03000e+00, 0.00000e+00, 4.15000e-01,\n",
       "        7.61000e+00, 1.57000e+01, 6.27000e+00, 2.00000e+00, 3.48000e+02,\n",
       "        1.47000e+01, 3.95380e+02, 3.11000e+00],\n",
       "       [4.89822e+00, 0.00000e+00, 1.81000e+01, 0.00000e+00, 6.31000e-01,\n",
       "        4.97000e+00, 1.00000e+02, 1.33250e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.75520e+02, 3.26000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=13, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Train on 404 samples, validate on 102 samples\n",
      "Epoch 1/15\n",
      "404/404 [==============================] - 0s 261us/sample - loss: 43.7268 - val_loss: 40.8057\n",
      "Epoch 2/15\n",
      "404/404 [==============================] - 0s 442us/sample - loss: 38.5713 - val_loss: 35.9014\n",
      "Epoch 3/15\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 34.4389 - val_loss: 32.4606\n",
      "Epoch 4/15\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 31.3055 - val_loss: 29.7386\n",
      "Epoch 5/15\n",
      "404/404 [==============================] - 0s 86us/sample - loss: 29.1025 - val_loss: 27.9347\n",
      "Epoch 6/15\n",
      "404/404 [==============================] - 0s 104us/sample - loss: 27.1864 - val_loss: 26.3800\n",
      "Epoch 7/15\n",
      "404/404 [==============================] - 0s 84us/sample - loss: 25.8099 - val_loss: 24.9541\n",
      "Epoch 8/15\n",
      "404/404 [==============================] - 0s 116us/sample - loss: 24.6911 - val_loss: 23.9697\n",
      "Epoch 9/15\n",
      "404/404 [==============================] - 0s 84us/sample - loss: 23.7583 - val_loss: 23.2427\n",
      "Epoch 10/15\n",
      "404/404 [==============================] - 0s 101us/sample - loss: 22.8885 - val_loss: 22.6556\n",
      "Epoch 11/15\n",
      "404/404 [==============================] - 0s 94us/sample - loss: 22.1866 - val_loss: 22.0410\n",
      "Epoch 12/15\n",
      "404/404 [==============================] - 0s 165us/sample - loss: 21.6180 - val_loss: 21.5341\n",
      "Epoch 13/15\n",
      "404/404 [==============================] - 0s 126us/sample - loss: 21.0501 - val_loss: 21.1547\n",
      "Epoch 14/15\n",
      "404/404 [==============================] - 0s 148us/sample - loss: 20.6206 - val_loss: 21.0894\n",
      "Epoch 15/15\n",
      "404/404 [==============================] - 0s 96us/sample - loss: 20.0578 - val_loss: 20.6551\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "results = model.fit(x = train_data,\n",
    "         y = train_targets,\n",
    "         epochs = 15,\n",
    "         validation_data=(test_data, test_targets),\n",
    "         callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "results.history.keys()\n",
    "sns.lineplot(x=[i for i in range(15)], y=results.history['loss'])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression().fit(train_data, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213535934621551"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.score(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = regression.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.shape == test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((test_pred - test_targets)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean squared error: 23.19559925642299\n"
     ]
    }
   ],
   "source": [
    "print(\"the mean squared error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.192179</td>\n",
       "      <td>0.397419</td>\n",
       "      <td>-0.050828</td>\n",
       "      <td>0.405765</td>\n",
       "      <td>-0.217597</td>\n",
       "      <td>0.344410</td>\n",
       "      <td>-0.378590</td>\n",
       "      <td>0.609689</td>\n",
       "      <td>0.575652</td>\n",
       "      <td>0.273447</td>\n",
       "      <td>-0.390613</td>\n",
       "      <td>0.434384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.192179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533823</td>\n",
       "      <td>-0.041981</td>\n",
       "      <td>-0.521713</td>\n",
       "      <td>0.338683</td>\n",
       "      <td>-0.578728</td>\n",
       "      <td>0.650787</td>\n",
       "      <td>-0.311091</td>\n",
       "      <td>-0.303522</td>\n",
       "      <td>-0.403139</td>\n",
       "      <td>0.176006</td>\n",
       "      <td>-0.415237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.397419</td>\n",
       "      <td>-0.533823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052839</td>\n",
       "      <td>0.774200</td>\n",
       "      <td>-0.409924</td>\n",
       "      <td>0.656350</td>\n",
       "      <td>-0.725155</td>\n",
       "      <td>0.599226</td>\n",
       "      <td>0.701362</td>\n",
       "      <td>0.379284</td>\n",
       "      <td>-0.372885</td>\n",
       "      <td>0.603129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.050828</td>\n",
       "      <td>-0.041981</td>\n",
       "      <td>0.052839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079803</td>\n",
       "      <td>0.040431</td>\n",
       "      <td>0.080488</td>\n",
       "      <td>-0.083101</td>\n",
       "      <td>-0.024851</td>\n",
       "      <td>-0.051343</td>\n",
       "      <td>-0.122008</td>\n",
       "      <td>0.037832</td>\n",
       "      <td>-0.011017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.405765</td>\n",
       "      <td>-0.521713</td>\n",
       "      <td>0.774200</td>\n",
       "      <td>0.079803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.335866</td>\n",
       "      <td>0.729338</td>\n",
       "      <td>-0.777062</td>\n",
       "      <td>0.616535</td>\n",
       "      <td>0.673471</td>\n",
       "      <td>0.188160</td>\n",
       "      <td>-0.409479</td>\n",
       "      <td>0.592994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.217597</td>\n",
       "      <td>0.338683</td>\n",
       "      <td>-0.409924</td>\n",
       "      <td>0.040431</td>\n",
       "      <td>-0.335866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240875</td>\n",
       "      <td>0.233970</td>\n",
       "      <td>-0.243990</td>\n",
       "      <td>-0.307904</td>\n",
       "      <td>-0.367256</td>\n",
       "      <td>0.145525</td>\n",
       "      <td>-0.610844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.344410</td>\n",
       "      <td>-0.578728</td>\n",
       "      <td>0.656350</td>\n",
       "      <td>0.080488</td>\n",
       "      <td>0.729338</td>\n",
       "      <td>-0.240875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.766670</td>\n",
       "      <td>0.462188</td>\n",
       "      <td>0.512746</td>\n",
       "      <td>0.282193</td>\n",
       "      <td>-0.278403</td>\n",
       "      <td>0.590898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.378590</td>\n",
       "      <td>0.650787</td>\n",
       "      <td>-0.725155</td>\n",
       "      <td>-0.083101</td>\n",
       "      <td>-0.777062</td>\n",
       "      <td>0.233970</td>\n",
       "      <td>-0.766670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.511179</td>\n",
       "      <td>-0.543668</td>\n",
       "      <td>-0.243067</td>\n",
       "      <td>0.295995</td>\n",
       "      <td>-0.507075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.609689</td>\n",
       "      <td>-0.311091</td>\n",
       "      <td>0.599226</td>\n",
       "      <td>-0.024851</td>\n",
       "      <td>0.616535</td>\n",
       "      <td>-0.243990</td>\n",
       "      <td>0.462188</td>\n",
       "      <td>-0.511179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922676</td>\n",
       "      <td>0.449908</td>\n",
       "      <td>-0.478245</td>\n",
       "      <td>0.490250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.575652</td>\n",
       "      <td>-0.303522</td>\n",
       "      <td>0.701362</td>\n",
       "      <td>-0.051343</td>\n",
       "      <td>0.673471</td>\n",
       "      <td>-0.307904</td>\n",
       "      <td>0.512746</td>\n",
       "      <td>-0.543668</td>\n",
       "      <td>0.922676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440499</td>\n",
       "      <td>-0.471777</td>\n",
       "      <td>0.534752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.273447</td>\n",
       "      <td>-0.403139</td>\n",
       "      <td>0.379284</td>\n",
       "      <td>-0.122008</td>\n",
       "      <td>0.188160</td>\n",
       "      <td>-0.367256</td>\n",
       "      <td>0.282193</td>\n",
       "      <td>-0.243067</td>\n",
       "      <td>0.449908</td>\n",
       "      <td>0.440499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.178060</td>\n",
       "      <td>0.365873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.390613</td>\n",
       "      <td>0.176006</td>\n",
       "      <td>-0.372885</td>\n",
       "      <td>0.037832</td>\n",
       "      <td>-0.409479</td>\n",
       "      <td>0.145525</td>\n",
       "      <td>-0.278403</td>\n",
       "      <td>0.295995</td>\n",
       "      <td>-0.478245</td>\n",
       "      <td>-0.471777</td>\n",
       "      <td>-0.178060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.376081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.434384</td>\n",
       "      <td>-0.415237</td>\n",
       "      <td>0.603129</td>\n",
       "      <td>-0.011017</td>\n",
       "      <td>0.592994</td>\n",
       "      <td>-0.610844</td>\n",
       "      <td>0.590898</td>\n",
       "      <td>-0.507075</td>\n",
       "      <td>0.490250</td>\n",
       "      <td>0.534752</td>\n",
       "      <td>0.365873</td>\n",
       "      <td>-0.376081</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   1.000000 -0.192179  0.397419 -0.050828  0.405765 -0.217597  0.344410   \n",
       "1  -0.192179  1.000000 -0.533823 -0.041981 -0.521713  0.338683 -0.578728   \n",
       "2   0.397419 -0.533823  1.000000  0.052839  0.774200 -0.409924  0.656350   \n",
       "3  -0.050828 -0.041981  0.052839  1.000000  0.079803  0.040431  0.080488   \n",
       "4   0.405765 -0.521713  0.774200  0.079803  1.000000 -0.335866  0.729338   \n",
       "5  -0.217597  0.338683 -0.409924  0.040431 -0.335866  1.000000 -0.240875   \n",
       "6   0.344410 -0.578728  0.656350  0.080488  0.729338 -0.240875  1.000000   \n",
       "7  -0.378590  0.650787 -0.725155 -0.083101 -0.777062  0.233970 -0.766670   \n",
       "8   0.609689 -0.311091  0.599226 -0.024851  0.616535 -0.243990  0.462188   \n",
       "9   0.575652 -0.303522  0.701362 -0.051343  0.673471 -0.307904  0.512746   \n",
       "10  0.273447 -0.403139  0.379284 -0.122008  0.188160 -0.367256  0.282193   \n",
       "11 -0.390613  0.176006 -0.372885  0.037832 -0.409479  0.145525 -0.278403   \n",
       "12  0.434384 -0.415237  0.603129 -0.011017  0.592994 -0.610844  0.590898   \n",
       "\n",
       "          7         8         9         10        11        12  \n",
       "0  -0.378590  0.609689  0.575652  0.273447 -0.390613  0.434384  \n",
       "1   0.650787 -0.311091 -0.303522 -0.403139  0.176006 -0.415237  \n",
       "2  -0.725155  0.599226  0.701362  0.379284 -0.372885  0.603129  \n",
       "3  -0.083101 -0.024851 -0.051343 -0.122008  0.037832 -0.011017  \n",
       "4  -0.777062  0.616535  0.673471  0.188160 -0.409479  0.592994  \n",
       "5   0.233970 -0.243990 -0.307904 -0.367256  0.145525 -0.610844  \n",
       "6  -0.766670  0.462188  0.512746  0.282193 -0.278403  0.590898  \n",
       "7   1.000000 -0.511179 -0.543668 -0.243067  0.295995 -0.507075  \n",
       "8  -0.511179  1.000000  0.922676  0.449908 -0.478245  0.490250  \n",
       "9  -0.543668  0.922676  1.000000  0.440499 -0.471777  0.534752  \n",
       "10 -0.243067  0.449908  0.440499  1.000000 -0.178060  0.365873  \n",
       "11  0.295995 -0.478245 -0.471777 -0.178060  1.000000 -0.376081  \n",
       "12 -0.507075  0.490250  0.534752  0.365873 -0.376081  1.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(train_data).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing accuracy:\n",
    "\n",
    "The neural network begins with lower accuracy, but reaches superior performance around the 10th epoch and goes on to exceed linear regression accuracy."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#encoder = OneHotEncoder()\n",
    "#y_train = y_train.reshape(-1, 1)\n",
    "#y_test = y_test.reshape(-1, 1)\n",
    "#encoder.fit(y_train)\n",
    "#y_train = encoder.transform(y_train)\n",
    "#y_test = encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.5785 - accuracy: 0.7954 - val_loss: 0.4838 - val_accuracy: 0.8335\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4149 - accuracy: 0.8502 - val_loss: 0.4386 - val_accuracy: 0.8389\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3789 - accuracy: 0.8626 - val_loss: 0.4016 - val_accuracy: 0.8562\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3588 - accuracy: 0.8688 - val_loss: 0.4213 - val_accuracy: 0.8500\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.3408 - accuracy: 0.8758 - val_loss: 0.4184 - val_accuracy: 0.8459\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3299 - accuracy: 0.8787 - val_loss: 0.3781 - val_accuracy: 0.8630\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3206 - accuracy: 0.8824 - val_loss: 0.3821 - val_accuracy: 0.8627\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3115 - accuracy: 0.8856 - val_loss: 0.3648 - val_accuracy: 0.8688\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3054 - accuracy: 0.8869 - val_loss: 0.3654 - val_accuracy: 0.8649\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2976 - accuracy: 0.8894 - val_loss: 0.3793 - val_accuracy: 0.8631\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.2911 - accuracy: 0.8914 - val_loss: 0.3760 - val_accuracy: 0.8623\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2863 - accuracy: 0.8928 - val_loss: 0.3890 - val_accuracy: 0.8634\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.2806 - accuracy: 0.8951 - val_loss: 0.3637 - val_accuracy: 0.8719\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2746 - accuracy: 0.8966 - val_loss: 0.3671 - val_accuracy: 0.8712\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2721 - accuracy: 0.8988 - val_loss: 0.3502 - val_accuracy: 0.8782\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2681 - accuracy: 0.9000 - val_loss: 0.3613 - val_accuracy: 0.8746\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2614 - accuracy: 0.9025 - val_loss: 0.3641 - val_accuracy: 0.8743\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2604 - accuracy: 0.9026 - val_loss: 0.3792 - val_accuracy: 0.8706\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2566 - accuracy: 0.9036 - val_loss: 0.3629 - val_accuracy: 0.8752\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2530 - accuracy: 0.9047 - val_loss: 0.3639 - val_accuracy: 0.8738\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2501 - accuracy: 0.9061 - val_loss: 0.3644 - val_accuracy: 0.8755\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2460 - accuracy: 0.9074 - val_loss: 0.3740 - val_accuracy: 0.8730\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2431 - accuracy: 0.9083 - val_loss: 0.3690 - val_accuracy: 0.8766\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2409 - accuracy: 0.9098 - val_loss: 0.3735 - val_accuracy: 0.8756\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2375 - accuracy: 0.9114 - val_loss: 0.3862 - val_accuracy: 0.8719\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.2355 - accuracy: 0.9118 - val_loss: 0.3969 - val_accuracy: 0.8672\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2331 - accuracy: 0.9119 - val_loss: 0.3755 - val_accuracy: 0.8755\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.2320 - accuracy: 0.9123 - val_loss: 0.3802 - val_accuracy: 0.8707\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.2283 - accuracy: 0.9131 - val_loss: 0.3778 - val_accuracy: 0.8740\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.2265 - accuracy: 0.9153 - val_loss: 0.3664 - val_accuracy: 0.8793\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2238 - accuracy: 0.9158 - val_loss: 0.3930 - val_accuracy: 0.8716\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2210 - accuracy: 0.9165 - val_loss: 0.3755 - val_accuracy: 0.8776\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.2213 - accuracy: 0.9164 - val_loss: 0.3924 - val_accuracy: 0.8730\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2189 - accuracy: 0.9171 - val_loss: 0.3990 - val_accuracy: 0.8706\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2154 - accuracy: 0.9192 - val_loss: 0.3910 - val_accuracy: 0.8779\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.2150 - accuracy: 0.9179 - val_loss: 0.3912 - val_accuracy: 0.8774\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.2139 - accuracy: 0.9201 - val_loss: 0.3809 - val_accuracy: 0.8800\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.2125 - accuracy: 0.9201 - val_loss: 0.3993 - val_accuracy: 0.8737\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.2099 - accuracy: 0.9213 - val_loss: 0.4372 - val_accuracy: 0.8660\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2106 - accuracy: 0.9201 - val_loss: 0.3870 - val_accuracy: 0.8804\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.2091 - accuracy: 0.9205 - val_loss: 0.3991 - val_accuracy: 0.8767\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.2061 - accuracy: 0.9221 - val_loss: 0.4100 - val_accuracy: 0.8724\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2051 - accuracy: 0.9224 - val_loss: 0.3831 - val_accuracy: 0.8793\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2035 - accuracy: 0.9226 - val_loss: 0.4160 - val_accuracy: 0.8755\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.2028 - accuracy: 0.9242 - val_loss: 0.4139 - val_accuracy: 0.8761\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.2002 - accuracy: 0.9243 - val_loss: 0.4122 - val_accuracy: 0.8761\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.1994 - accuracy: 0.9252 - val_loss: 0.4175 - val_accuracy: 0.8789\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.1987 - accuracy: 0.9246 - val_loss: 0.4187 - val_accuracy: 0.8742\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.1969 - accuracy: 0.9243 - val_loss: 0.4161 - val_accuracy: 0.8756\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.1960 - accuracy: 0.9261 - val_loss: 0.4132 - val_accuracy: 0.8786\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(30, activation = 'relu', input_dim=784),\n",
    "    Dense(15, activation = 'relu'),\n",
    "    Dense(30, activation = 'relu'),\n",
    "    Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "         \n",
    "results = model.fit(x_train, y_train, \n",
    "                    verbose = 1, \n",
    "                    epochs = 50,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(x=[i for i in range(len(results.history[\"val_accuracy\"]))], y=results.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.8078 - accuracy: 0.7097 - val_loss: 0.4875 - val_accuracy: 0.8272\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.5589 - accuracy: 0.8031 - val_loss: 0.4408 - val_accuracy: 0.8464\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.5140 - accuracy: 0.8198 - val_loss: 0.4424 - val_accuracy: 0.8418\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.4891 - accuracy: 0.8278 - val_loss: 0.4214 - val_accuracy: 0.8532\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.4713 - accuracy: 0.8342 - val_loss: 0.4021 - val_accuracy: 0.8573\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4619 - accuracy: 0.8368 - val_loss: 0.4056 - val_accuracy: 0.8562\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.4519 - accuracy: 0.8404 - val_loss: 0.3964 - val_accuracy: 0.8610\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.4442 - accuracy: 0.8421 - val_loss: 0.4046 - val_accuracy: 0.8583\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4390 - accuracy: 0.8447 - val_loss: 0.4019 - val_accuracy: 0.8622\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.4325 - accuracy: 0.8462 - val_loss: 0.4044 - val_accuracy: 0.8576\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.4269 - accuracy: 0.8494 - val_loss: 0.3792 - val_accuracy: 0.8670\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.4251 - accuracy: 0.8491 - val_loss: 0.3869 - val_accuracy: 0.8623\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4167 - accuracy: 0.8516 - val_loss: 0.3857 - val_accuracy: 0.8632\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.4152 - accuracy: 0.8532 - val_loss: 0.3785 - val_accuracy: 0.8635\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.4130 - accuracy: 0.8524 - val_loss: 0.3813 - val_accuracy: 0.8656\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "\n",
    "stop = EarlyStopping(monitor='val_accuracy', \n",
    "                              min_delta=.01, \n",
    "                              patience=10)\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(30, activation = 'relu', input_dim=784),\n",
    "    Dropout(.2),\n",
    "    Dense(15, activation = 'relu'),\n",
    "    Dropout(.1),\n",
    "    Dense(30, activation = 'relu'),\n",
    "    Dropout(.1),\n",
    "    Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'nadam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "         \n",
    "results = model.fit(x_train, y_train, \n",
    "                    verbose = 1, \n",
    "                    epochs = 50,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[tensorboard_callback, stop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "U4-S2-NN (Python3)",
   "language": "python",
   "name": "u4-s2-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
